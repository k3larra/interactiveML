{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ToDo\n",
    "1. ~~Randomly select validation data from the teaching data and retrain~~\n",
    "1. ~~Test towards test set~~\n",
    "1. Do for all users\n",
    "1. Note result\n",
    "1. Teroi; Can I train without validation data?\n",
    "1. Define and udnertand training cycles and epochs \n",
    "1. Use Cross vadidation, data augumentation.\n",
    "1. Save and reload model\n",
    "1. Te0ri what is the differens retraining with all or only parts. Should I incrementally add training for every week or retrain on all? \n",
    "1. Spara trained model and reload it. \n",
    "\n",
    "\n",
    "Upgrade Jupyter lab will all features \n",
    "\n",
    "misc\n",
    "the oneshot learning stuff is outlined here:\n",
    "https://forums.fast.ai/t/the-1cycle-policy-an-experiment-that-investigate-super-convergence-phenomenon-described-in-leslie-smiths-research/14737"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting Underfitting\n",
    "\n",
    "1: Overfitting if: validation loss >> training loss\n",
    "\n",
    "2: Underfitting if: training loss >> validation loss\n",
    "\n",
    "* Typically validation loss should be similar to but slightly higher than training loss. As long as validation loss is lower than or even equal to training loss one should keep doing more training.\n",
    "* If training loss is reducing without increase in validation loss then again keep doing more training\n",
    "* If validation loss starts increasing then it is time to stop\n",
    "* If overall accuracy still not acceptable then review mistakes model is making and think of what can one change:\n",
    "    * More data? More / different data augmentations? Generative data?\n",
    "    * Different architecture?\n",
    "\n",
    "--\n",
    "Jeremy\n",
    "Jeremy Howard (Admin)\n",
    "Nov '17\n",
    "Funnily enough, some over-fitting is nearly always a good thing. All that matters in the end is: is the validation loss as low as you can get it (and/or the val accuracy as high)? This often occurs when the training loss is quite a bit lower.\n",
    "\n",
    "1) Your model performs better on the training data than on the unknown validation data. A bit of overfitting is normal, but higher amounts need to be regulated with techniques like dropout to ensure generalization.\n",
    "\n",
    "2) Your model performs better on the validation data. This can happen when you use augmentation on the training data, making it harder to predict in comparison to the unmodified validation samples. It can also happen when your training loss is calculated as a moving average over 1 epoch, whereas the validation loss is calculated after the learning phase of the same epoch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "Dropout throws away some of the activations in the layers. This way overfitting is avoided.\n",
    "If you throw away a lot it cannot overfit but your accuracy will not be very good.\n",
    "On the validation set dropout not used thats why validation loss is better that my training loss initially.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cycle length\n",
    "The cycle_len and cycle_mult parameters are used for doing a variation on stochastic gradient descent called “stochastic gradient descent with restarts” (SGDR).\n",
    "\n",
    "This blog post 366 by @mark-hoffmann gives a nice overview, but briefly, the idea is to start doing our usual minibatch gradient descent with a given learning rate (lr), while gradually decreasing it (the fast.ai 7 library uses “cosine annealing”)… until we jump it back up to lr!\n",
    "\n",
    "The cycle_len parameter governs how long we’re going to ride that cosine curve as we decrease… decrease… decrease… the learning rate. Cycles are measured in epochs, so cycle_len=1 by itself would mean to continually decrease the learning rate over the course of one epoch, and then jump it back up. The cycle_mult parameter says to multiply the length of a cycle by something (in this case, 2) as soon as you finish one.\n",
    "\n",
    "So, here we’re going to do three cycles, of lengths (in epochs): 1, 2, and 4. So, 7 epochs in total, but our SGDR only restarts twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define \n",
    "\n",
    "* Epoch\n",
    "* Iterations\n",
    "* Learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
